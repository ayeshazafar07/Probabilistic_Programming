---
title: "Assignment 5 Report"
author: "Ayesha Zafar"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

# 5. MCMC: AR(1)

---

### **5.1 Build a random-walk Metropolis-Hastings sampler that generates samples from the posterior p(ϕ,σ|X). Generate the proposals (ϕ∗,log(σ)∗) from a multivariate normal distribution with covariance τI, where τ is a bivariate vector, and I the identity matrix. In other words, the proposals for σ are generated on log scale, so there is no need to worry about negative proposals. Choose elements of τ suitable values. You can assume the proposal distribution is symmetrical. Use the sampler to estimate ϕ and σ from the data in “time_series.txt”. It’s enough to use a single chain, but choose a sufficient number of samples.**

```{r}
library(MASS)

# Loading data from time_series.txt
data <- scan("time_series.txt")
head(data)
```

Computing log-likelihood based on AR(1) model definition:

xi ∼ N(ϕxi−1,σ^2)

and residuals are calculated as:

residuals = xi−ϕxi−1
 
The likelihood will capture how well ϕ and σ explain observed data.

```{r}
log_likelihood <- function(phi, sigma, data) {
  n <- length(data)
  residuals <- data[-1] - phi * data[-n]
  return(-0.5 * sum(log(2 * pi * sigma^2) + (residuals^2) / sigma^2))
}
```

The prior distribution can explain prior beliefs about parameters:

- 𝜙∼ Uniform(−1,1), which ensures stationarity of the AR(1) process.

- log(σ) ∼ Normal(0,10), placing a log-normal prior on σ.

```{r}

log_prior <- function(phi, sigma) {
  if (phi < -1 || phi > 1 || sigma <= 0) {
    return(-Inf)
  }
  log_sigma <- log(sigma)
  return(dunif(phi, -1, 1, log = TRUE) + dnorm(log_sigma, 0, 10, log = TRUE))
}
```

Posterior distribution combines the likelihood and prior:

logp(ϕ,σ∣data) = log-likelihood +log-prior

```{r}
log_posterior <- function(phi, sigma, data) {
  return(log_likelihood(phi, sigma, data) + log_prior(phi, sigma))
}
```

Metropolis-Hastings algorithm generates samples from the posterior distribution using following steps:

1. Proposing new values (ϕ∗,log(σ)∗) from a multivariate normal distribution with covariance matrix 𝜏I, where 𝜏 controls the proposal scale.

2. Calculating acceptance probability using formula r = min(1, (p(ϕ,σ*∣data)/p(ϕ,σ ∣data)))

3. Accepting or rejecting proposals based on a random draw from a uniform distribution.

```{r}
metropolis_sampler <- function(data, n_samples, tau) {
  # Setting initial values
  phi <- runif(1, -1, 1)
  sigma <- runif(1, 0.1, 1)
  log_sigma <- log(sigma)
  
  # Setting up a storage
  samples <- matrix(NA, nrow = n_samples, ncol = 2)
  accepted <- 0
  
  for (i in 1:n_samples) {
    # Step 1. Proposing new values
    proposal <- mvrnorm(1, mu = c(phi, log_sigma), Sigma = diag(tau, 2))
    phi_star <- proposal[1]
    log_sigma_star <- proposal[2]
    sigma_star <- exp(log_sigma_star)
    
    # Step 2. Calculating acceptance ratio
    log_r <- log_posterior(phi_star, sigma_star, data) - log_posterior(phi, sigma, data)
    
    # Step 3. Accepting or rejecting proposals
    if (log(runif(1)) < log_r) {
      phi <- phi_star
      log_sigma <- log_sigma_star
      sigma <- sigma_star
      accepted <- accepted + 1
    }
    
    # Storing sample in list
    samples[i, ] <- c(phi, sigma)
  }
  
  list(samples = samples, acceptance_rate = accepted / n_samples)
}
```

Creating summary of the results

```{r}
# Running sampler first
n_samples <- 10000
# Proposal scale
tau <- c(0.1, 0.1) 
results <- metropolis_sampler(data, n_samples, tau)

# Extracting samples and acceptance rate from results
samples <- results$samples
acceptance_rate <- results$acceptance_rate

# Summarizing and printing posterior
phi_samples <- samples[, 1]
sigma_samples <- samples[, 2]

phi_mean <- mean(phi_samples)
phi_ci <- quantile(phi_samples, c(0.025, 0.975))
sigma_mean <- mean(sigma_samples)
sigma_ci <- quantile(sigma_samples, c(0.025, 0.975))

summary_table <- data.frame(
  Parameter = c("Phi", "Sigma"),
  Mean = c(phi_mean, sigma_mean),
  `2.5%` = c(phi_ci[1], sigma_ci[1]),
  `97.5%` = c(phi_ci[2], sigma_ci[2])
)
print(summary_table)
```

Visualizing using Trace plots as they show evolution of samples over iterations (helping assess convergence)

```{r}
library(ggplot2)

phi_trace <- data.frame(Iteration = 1:n_samples, Phi = phi_samples)
ggplot(phi_trace, aes(x = Iteration, y = Phi)) +
  geom_line(color = "purple") +
  labs(title = "Trace Plot for Phi", x = "Iteration", y = "Phi")

sigma_trace <- data.frame(Iteration = 1:n_samples, Sigma = sigma_samples)
ggplot(sigma_trace, aes(x = Iteration, y = Sigma)) +
  geom_line(color = "red") +
  labs(title = "Trace Plot for Sigma", x = "Iteration", y = "Sigma")
```

Visualizing the joint distribution of 𝜙 and σ using a scatter plot.

```{r}
phi_sigma_df <- data.frame(Phi = phi_samples, Sigma = sigma_samples)
ggplot(phi_sigma_df, aes(x = Phi, y = Sigma)) +
  geom_point(alpha = 0.5,color = "darkgreen") +
  labs(title = "Joint Distribution of Phi and Sigma", x = "Phi", y = "Sigma")
```

### **5.2 Plot the trajectory of samples in (ϕ,σ) space.**

```{r}
plot(
  samples[, 1], samples[, 2],
  type = "l", col = "blue", 
  xlab = expression(phi), ylab = expression(sigma),
  main = "Trajectory in (ϕ,σ) space"
)
```

## **5.3 Compute the acceptance ratio of the sampler (ratio of accepted and rejected proposals).**

```{r}
set.seed(42)
results <- metropolis_sampler(data, n_samples = 10000, tau = c(0.1, 0.1))
samples <- results$samples
acceptance_rate <- results$acceptance_rate
cat("Acceptance Rate:", acceptance_rate, "\n")
```

Ratio of accepted and rejected proposals.

```{r}
total_proposals <- 10000
rejected <- total_proposals - (acceptance_rate * total_proposals)
cat("Accepted:", acceptance_rate * total_proposals, 
    "Rejected:", rejected, 
    "Ratio (Accepted:Rejected):", acceptance_rate / (1 - acceptance_rate), "\n")
```


**References**

- https://eriqande.github.io/sisg_mcmc_course/s03-01-intro-mcmc-in-R.nb.html

- https://www.rdocumentation.org/packages/fmcmc/versions/0.5-2/topics/MCMC

- https://search.r-project.org/CRAN/refmans/insight/html/get_loglikelihood.html

- https://www.quora.com/What-is-the-definition-of-prior-distribution-and-posterior-distribution

- https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm

- https://rpubs.com/ROARMarketingConcepts/1063733


