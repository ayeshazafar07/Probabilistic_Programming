---
title: "Assignment 5 Report"
author: "Ayesha Zafar"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

# 5. MCMC: AR(1)

---

### **5.1 Build a random-walk Metropolis-Hastings sampler that generates samples from the posterior p(Ï•,Ïƒ|X). Generate the proposals (Ï•âˆ—,log(Ïƒ)âˆ—) from a multivariate normal distribution with covariance Ï„I, where Ï„ is a bivariate vector, and I the identity matrix. In other words, the proposals for Ïƒ are generated on log scale, so there is no need to worry about negative proposals. Choose elements of Ï„ suitable values. You can assume the proposal distribution is symmetrical. Use the sampler to estimate Ï• and Ïƒ from the data in â€œtime_series.txtâ€. Itâ€™s enough to use a single chain, but choose a sufficient number of samples.**

```{r}
library(MASS)

# Loading data from time_series.txt
data <- scan("time_series.txt")
head(data)
```

Computing log-likelihood based on AR(1) model definition:

xi âˆ¼ N(Ï•xiâˆ’1,Ïƒ^2)

and residuals are calculated as:

residuals = xiâˆ’Ï•xiâˆ’1
 
The likelihood will capture how well Ï• and Ïƒ explain observed data.

```{r}
log_likelihood <- function(phi, sigma, data) {
  n <- length(data)
  residuals <- data[-1] - phi * data[-n]
  return(-0.5 * sum(log(2 * pi * sigma^2) + (residuals^2) / sigma^2))
}
```

The prior distribution can explain prior beliefs about parameters:

- ğœ™âˆ¼ Uniform(âˆ’1,1), which ensures stationarity of the AR(1) process.

- log(Ïƒ) âˆ¼ Normal(0,10), placing a log-normal prior on Ïƒ.

```{r}

log_prior <- function(phi, sigma) {
  if (phi < -1 || phi > 1 || sigma <= 0) {
    return(-Inf)
  }
  log_sigma <- log(sigma)
  return(dunif(phi, -1, 1, log = TRUE) + dnorm(log_sigma, 0, 10, log = TRUE))
}
```

Posterior distribution combines the likelihood and prior:

logp(Ï•,Ïƒâˆ£data) = log-likelihood +log-prior

```{r}
log_posterior <- function(phi, sigma, data) {
  return(log_likelihood(phi, sigma, data) + log_prior(phi, sigma))
}
```

Metropolis-Hastings algorithm generates samples from the posterior distribution using following steps:

1. Proposing new values (Ï•âˆ—,log(Ïƒ)âˆ—) from a multivariate normal distribution with covariance matrix ğœI, where ğœ controls the proposal scale.

2. Calculating acceptance probability using formula r = min(1, (p(Ï•,Ïƒ*âˆ£data)/p(Ï•,Ïƒ âˆ£data)))

3. Accepting or rejecting proposals based on a random draw from a uniform distribution.

```{r}
metropolis_sampler <- function(data, n_samples, tau) {
  # Setting initial values
  phi <- runif(1, -1, 1)
  sigma <- runif(1, 0.1, 1)
  log_sigma <- log(sigma)
  
  # Setting up a storage
  samples <- matrix(NA, nrow = n_samples, ncol = 2)
  accepted <- 0
  
  for (i in 1:n_samples) {
    # Step 1. Proposing new values
    proposal <- mvrnorm(1, mu = c(phi, log_sigma), Sigma = diag(tau, 2))
    phi_star <- proposal[1]
    log_sigma_star <- proposal[2]
    sigma_star <- exp(log_sigma_star)
    
    # Step 2. Calculating acceptance ratio
    log_r <- log_posterior(phi_star, sigma_star, data) - log_posterior(phi, sigma, data)
    
    # Step 3. Accepting or rejecting proposals
    if (log(runif(1)) < log_r) {
      phi <- phi_star
      log_sigma <- log_sigma_star
      sigma <- sigma_star
      accepted <- accepted + 1
    }
    
    # Storing sample in list
    samples[i, ] <- c(phi, sigma)
  }
  
  list(samples = samples, acceptance_rate = accepted / n_samples)
}
```

Creating summary of the results

```{r}
# Running sampler first
n_samples <- 10000
# Proposal scale
tau <- c(0.1, 0.1) 
results <- metropolis_sampler(data, n_samples, tau)

# Extracting samples and acceptance rate from results
samples <- results$samples
acceptance_rate <- results$acceptance_rate

# Summarizing and printing posterior
phi_samples <- samples[, 1]
sigma_samples <- samples[, 2]

phi_mean <- mean(phi_samples)
phi_ci <- quantile(phi_samples, c(0.025, 0.975))
sigma_mean <- mean(sigma_samples)
sigma_ci <- quantile(sigma_samples, c(0.025, 0.975))

summary_table <- data.frame(
  Parameter = c("Phi", "Sigma"),
  Mean = c(phi_mean, sigma_mean),
  `2.5%` = c(phi_ci[1], sigma_ci[1]),
  `97.5%` = c(phi_ci[2], sigma_ci[2])
)
print(summary_table)
```

Visualizing using Trace plots as they show evolution of samples over iterations (helping assess convergence)

```{r}
library(ggplot2)

phi_trace <- data.frame(Iteration = 1:n_samples, Phi = phi_samples)
ggplot(phi_trace, aes(x = Iteration, y = Phi)) +
  geom_line(color = "purple") +
  labs(title = "Trace Plot for Phi", x = "Iteration", y = "Phi")

sigma_trace <- data.frame(Iteration = 1:n_samples, Sigma = sigma_samples)
ggplot(sigma_trace, aes(x = Iteration, y = Sigma)) +
  geom_line(color = "red") +
  labs(title = "Trace Plot for Sigma", x = "Iteration", y = "Sigma")
```

Visualizing the joint distribution of ğœ™ and Ïƒ using a scatter plot.

```{r}
phi_sigma_df <- data.frame(Phi = phi_samples, Sigma = sigma_samples)
ggplot(phi_sigma_df, aes(x = Phi, y = Sigma)) +
  geom_point(alpha = 0.5,color = "darkgreen") +
  labs(title = "Joint Distribution of Phi and Sigma", x = "Phi", y = "Sigma")
```

### **5.2 Plot the trajectory of samples in (Ï•,Ïƒ) space.**

```{r}
plot(
  samples[, 1], samples[, 2],
  type = "l", col = "blue", 
  xlab = expression(phi), ylab = expression(sigma),
  main = "Trajectory in (Ï•,Ïƒ) space"
)
```

## **5.3 Compute the acceptance ratio of the sampler (ratio of accepted and rejected proposals).**

```{r}
set.seed(42)
results <- metropolis_sampler(data, n_samples = 10000, tau = c(0.1, 0.1))
samples <- results$samples
acceptance_rate <- results$acceptance_rate
cat("Acceptance Rate:", acceptance_rate, "\n")
```

Ratio of accepted and rejected proposals.

```{r}
total_proposals <- 10000
rejected <- total_proposals - (acceptance_rate * total_proposals)
cat("Accepted:", acceptance_rate * total_proposals, 
    "Rejected:", rejected, 
    "Ratio (Accepted:Rejected):", acceptance_rate / (1 - acceptance_rate), "\n")
```


**References**

- https://eriqande.github.io/sisg_mcmc_course/s03-01-intro-mcmc-in-R.nb.html

- https://www.rdocumentation.org/packages/fmcmc/versions/0.5-2/topics/MCMC

- https://search.r-project.org/CRAN/refmans/insight/html/get_loglikelihood.html

- https://www.quora.com/What-is-the-definition-of-prior-distribution-and-posterior-distribution

- https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm

- https://rpubs.com/ROARMarketingConcepts/1063733


